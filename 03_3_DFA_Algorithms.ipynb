{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "318px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    },
    "colab": {
      "name": "03_3_DFA_Algorithms.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/croesusking/cse480-notebooks/blob/master/03_3_DFA_Algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cKQnKVcTICz"
      },
      "source": [
        "# DFA Algorithms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "QO9l0EdPTIC7"
      },
      "source": [
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "import sys\n",
        "\n",
        "# -- Detect if in Own Install or in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    OWN_INSTALL = False\n",
        "except:\n",
        "    OWN_INSTALL = True\n",
        "    \n",
        "if OWN_INSTALL:\n",
        "\n",
        "  sys.path[0:0] = ['../../../../..',  '../../../../../3rdparty',  \n",
        "                   '../../../..',  '../../../../3rdparty',  \n",
        "                   '../../..',     '../../../3rdparty', \n",
        "                   '../..',        '../../3rdparty',\n",
        "                   '..',           '../3rdparty' ]\n",
        "\n",
        "else: # In colab\n",
        "  ! if [ ! -d Jove ]; then git clone https://github.com/ganeshutah/Jove Jove; fi\n",
        "  sys.path.append('./Jove')\n",
        "  sys.path.append('./Jove/jove')\n",
        "\n",
        "# -- common imports --\n",
        "from jove.DotBashers import *\n",
        "from jove.Def_md2mc  import *\n",
        "from jove.Def_DFA    import *\n",
        "from jove.LangDef    import *  # for testing DFA actions\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "pFk__MFETIC8"
      },
      "source": [
        "def mkp_dfa(Q, Sigma, Delta, q0, F):\n",
        "    \"\"\"In : Traits of a DFA\n",
        "       Out: A DFA\n",
        "       Check for partial consistency of the given DFA traits.\n",
        "       If the check passes, make and return a DFA with a partial \n",
        "       Delta.\n",
        "    \"\"\"\n",
        "    newDFA = {\"Q\":Q, \"Sigma\":Sigma, \"Delta\":Delta, \"q0\":q0, \"F\":F}\n",
        "    assert(\n",
        "        is_partially_consistent_dfa(newDFA)\n",
        "    ), \"DFA given to mkp_dfa is not partially consistent. Plz check its components.\"\n",
        "    return(newDFA)\n",
        "\n",
        "def mk_dfa(Q, Sigma, Delta, q0, F):\n",
        "    \"\"\"In : Traits of a DFA\n",
        "       Out: A DFA\n",
        "       Check for structural consistency of the given DFA traits.\n",
        "       If the check passes, make and return a DFA with a total \n",
        "       Delta.\n",
        "    \"\"\"\n",
        "    newDFA = {\"Q\":Q, \"Sigma\":Sigma, \"Delta\":Delta, \"q0\":q0, \"F\":F}\n",
        "    assert(\n",
        "        is_consistent_dfa(newDFA)\n",
        "    ), \"DFA given to mk_dfa is not consistent. Plz check its components.\"\n",
        "    return(newDFA)\n",
        "\n",
        "def totalize_dfa(D):\n",
        "    \"\"\"In : Partially consistent DFA\n",
        "       Out: A consistent DFA \n",
        "       Given a partially specified DFA, make it total by \n",
        "       transitioning to state BH wherever the incoming Delta \n",
        "       has gaps. The returned DFA is structurally consistent.\n",
        "    \"\"\"\n",
        "    assert(\n",
        "        is_partially_consistent_dfa(D)\n",
        "    ), \"DFA given to totalize_dfa is not partially consistent.\"\n",
        "    if set(fn_dom(D[\"Delta\"])) == set(product(D[\"Q\"], D[\"Sigma\"])):\n",
        "        # It is already total!\n",
        "        return D \n",
        "    else:        \n",
        "        # We must introduce a BH state of not already present\n",
        "        # and proceed from there\n",
        "        incoming_Delta = D[\"Delta\"].copy()\n",
        "    \n",
        "        # Gaps in incoming_Delta's transition function are sent\n",
        "        # to the BH (black-hole) state\n",
        "        gaps_in_Tr = { (q,c) : \"BH\" for q in D[\"Q\"] for c in D[\"Sigma\"] \n",
        "                       if (q,c) not in D[\"Delta\"] }\n",
        "    \n",
        "        # We are gonna add a new black-hole-state.\n",
        "        # It must curl back to itself for every symbol in Sigma\n",
        "        bh_self_absorbent_moves = { (\"BH\", c): \"BH\" for c in D[\"Sigma\"] }\n",
        "\n",
        "        # Fill the gaps in incoming_Delta\n",
        "        incoming_Delta.update( gaps_in_Tr )\n",
        "    \n",
        "        # Add in the moves where the black-hole state curls \n",
        "        # back to itself\n",
        "        incoming_Delta.update( bh_self_absorbent_moves )\n",
        "        \n",
        "        # All updates required are accomplished\n",
        "        finished_Delta = incoming_Delta\n",
        "    \n",
        "        # See that we update D[\"Q\"] with the \"BH\" (black-hole) \n",
        "        # state; also return the fixed-up incoming_Delta\n",
        "        return {\"Q\"    : D[\"Q\"] | { \"BH\" }, \n",
        "                \"Sigma\": D[\"Sigma\"],    \n",
        "                \"Delta\": finished_Delta,\n",
        "                \"q0\"   : D[\"q0\"],          \n",
        "                \"F\"    : D[\"F\"] }\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9qi01oaTIC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc8ce80-9e12-4b20-ada1-adc1ae3d6132"
      },
      "source": [
        "DFA_B0 = md2mc('''DFA !! DFA for words beginning with 0's\n",
        "I : 0   -> F\n",
        "I : 1   -> B\n",
        "B : 0|1 -> B\n",
        "F : 0|1 -> F\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating LALR tables\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcVhhhQkTIC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefedf37-dad4-4663-bcf4-8f1c3394ed2f"
      },
      "source": [
        "DFA_B0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Delta': {('B', '0'): 'B',\n",
              "  ('B', '1'): 'B',\n",
              "  ('F', '0'): 'F',\n",
              "  ('F', '1'): 'F',\n",
              "  ('I', '0'): 'F',\n",
              "  ('I', '1'): 'B'},\n",
              " 'F': {'F'},\n",
              " 'Q': {'B', 'F', 'I'},\n",
              " 'Sigma': {'0', '1'},\n",
              " 'q0': 'I'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XBGjQ-XTIC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9d3dfcf-2e79-453f-a289-8b82b46c87b8"
      },
      "source": [
        "DFA_B0[\"Delta\"][('I','0')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'F'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLQphJZtTIC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "4fa8181d-9366-4977-a8d8-82b328359505"
      },
      "source": [
        "dotObj_dfa(DFA_B0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fe32fc97cc0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"227pt\" height=\"238pt\"\n viewBox=\"0.00 0.00 227.00 238.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 234)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-234 223,-234 223,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- I -->\n<g id=\"node3\" class=\"node\">\n<title>I</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"109\" cy=\"-84\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-80.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">I</text>\n</g>\n<!-- EMPTY&#45;&gt;I -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;I</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3048,-84C62.6909,-84 71.9407,-84 80.4103,-84\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.5976,-87.5001 90.5976,-84 80.5976,-80.5001 80.5976,-87.5001\"/>\n</g>\n<!-- B -->\n<g id=\"node2\" class=\"node\">\n<title>B</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"197\" cy=\"-146\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-142.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">B</text>\n</g>\n<!-- B&#45;&gt;B -->\n<g id=\"edge4\" class=\"edge\">\n<title>B&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M192.8654,-163.7817C192.1628,-173.3149 193.541,-182 197,-182 199.1078,-182 200.443,-178.7749 201.0054,-174.0981\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.509,-173.8248 201.1346,-163.7817 197.5096,-173.7371 204.509,-173.8248\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- B&#45;&gt;B -->\n<g id=\"edge5\" class=\"edge\">\n<title>B&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M190.3338,-162.8636C186.2877,-180.3779 188.5098,-200 197,-200 203.8983,-200 206.6587,-187.0463 205.281,-172.7944\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.7259,-172.1722 203.6662,-162.8636 201.8166,-173.2957 208.7259,-172.1722\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-203.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- I&#45;&gt;B -->\n<g id=\"edge3\" class=\"edge\">\n<title>I&#45;&gt;B</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M123.928,-94.5175C137.5817,-104.1371 157.9955,-118.5196 173.7789,-129.6397\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"171.8081,-132.5326 181.9988,-135.431 175.8398,-126.8102 171.8081,-132.5326\"/>\n<text text-anchor=\"middle\" x=\"151\" y=\"-119.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- F -->\n<g id=\"node4\" class=\"node\">\n<title>F</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"197\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"197\" cy=\"-22\" rx=\"22\" ry=\"22\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F</text>\n</g>\n<!-- I&#45;&gt;F -->\n<g id=\"edge2\" class=\"edge\">\n<title>I&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M123.928,-73.4825C136.6354,-64.5296 155.1985,-51.4511 170.4344,-40.7166\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"172.7923,-43.3369 178.9513,-34.7162 168.7606,-37.6145 172.7923,-43.3369\"/>\n<text text-anchor=\"middle\" x=\"151\" y=\"-61.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- F&#45;&gt;F -->\n<g id=\"edge6\" class=\"edge\">\n<title>F&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M192.7549,-43.8066C192.3506,-53.5625 193.7656,-62 197,-62 199.0215,-62 200.3323,-58.7041 200.9324,-53.8504\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.4321,-53.9107 201.2451,-43.8066 197.4355,-53.6928 204.4321,-53.9107\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-65.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- F&#45;&gt;F -->\n<g id=\"edge7\" class=\"edge\">\n<title>F&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M189.7985,-42.813C186.5135,-60.8838 188.9141,-80 197,-80 203.5698,-80 206.3864,-67.3803 205.4497,-52.9552\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.8968,-52.3106 204.2015,-42.813 201.9492,-53.1656 208.8968,-52.3106\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91q1hBgATIC_"
      },
      "source": [
        "DFA_E1 = md2mc('''DFA !! accepts words that end in a 1  \n",
        "I : 1   -> F\n",
        "I : 0   -> I\n",
        "F : 0|1 -> F\n",
        "''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYbvCrHBTIC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "d3e03d17-9612-47f3-b5c7-a181b076d1b8"
      },
      "source": [
        "dotObj_dfa(DFA_E1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fe32f908470>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"227pt\" height=\"118pt\"\n viewBox=\"0.00 0.00 227.00 118.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 114)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-114 223,-114 223,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- I -->\n<g id=\"node2\" class=\"node\">\n<title>I</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"109\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">I</text>\n</g>\n<!-- EMPTY&#45;&gt;I -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;I</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3048,-22C62.6909,-22 71.9407,-22 80.4103,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.5976,-25.5001 90.5976,-22 80.5976,-18.5001 80.5976,-25.5001\"/>\n</g>\n<!-- I&#45;&gt;I -->\n<g id=\"edge3\" class=\"edge\">\n<title>I&#45;&gt;I</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M102.6208,-39.0373C101.3189,-48.8579 103.4453,-58 109,-58 112.4717,-58 114.6042,-54.4289 115.3975,-49.3529\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"118.8971,-49.031 115.3792,-39.0373 111.8971,-49.0435 118.8971,-49.031\"/>\n<text text-anchor=\"middle\" x=\"109\" y=\"-61.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- F -->\n<g id=\"node3\" class=\"node\">\n<title>F</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"197\" cy=\"-22\" rx=\"18\" ry=\"18\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"197\" cy=\"-22\" rx=\"22\" ry=\"22\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-18.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">F</text>\n</g>\n<!-- I&#45;&gt;F -->\n<g id=\"edge2\" class=\"edge\">\n<title>I&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M127.2337,-22C138.0103,-22 151.9708,-22 164.5692,-22\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"164.7317,-25.5001 174.7317,-22 164.7317,-18.5001 164.7317,-25.5001\"/>\n<text text-anchor=\"middle\" x=\"151\" y=\"-25.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- F&#45;&gt;F -->\n<g id=\"edge4\" class=\"edge\">\n<title>F&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M192.7549,-43.8066C192.3506,-53.5625 193.7656,-62 197,-62 199.0215,-62 200.3323,-58.7041 200.9324,-53.8504\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.4321,-53.9107 201.2451,-43.8066 197.4355,-53.6928 204.4321,-53.9107\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-65.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- F&#45;&gt;F -->\n<g id=\"edge5\" class=\"edge\">\n<title>F&#45;&gt;F</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M189.7985,-42.813C186.5135,-60.8838 188.9141,-80 197,-80 203.5698,-80 206.3864,-67.3803 205.4497,-52.9552\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"208.8968,-52.3106 204.2015,-42.813 201.9492,-53.1656 208.8968,-52.3106\"/>\n<text text-anchor=\"middle\" x=\"197\" y=\"-83.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "cMpLPJ9VTIC_"
      },
      "source": [
        "def step_dfa(D, q, c):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "            q (state in D)\n",
        "            c (symbol in D's sigma)\n",
        "       Out: next state of q via c (state in D) \n",
        "    \"\"\"\n",
        "    assert(c in D[\"Sigma\"]), \"step_dfa given c not in Sigma.\"\n",
        "    assert(q in D[\"Q\"]), \"step_dfa given q not in Q.\"\n",
        "    return D[\"Delta\"][(q,c)]\n",
        "\n",
        "def run_dfa(D, s):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "            q (state in D)\n",
        "            s (string over D's sigma, including \"\")\n",
        "       Out: next state of q via s (state in D) \n",
        "    \"\"\"    \n",
        "    state = D[\"q0\"]\n",
        "    while s != \"\":\n",
        "        state = step_dfa(D, state, s[0])\n",
        "        s = s[1:]\n",
        "    return state\n",
        "\n",
        "def accepts_dfa(D, s):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "            s (string over D's sigma, including \"\")\n",
        "       Out: Boolean (if state after s-run is in D's final).\n",
        "    \"\"\"\n",
        "    return run_dfa(D, s) in D[\"F\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn1vbYSCTIDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476c7f1d-18e8-432b-f681-26e4c5948774"
      },
      "source": [
        "accepts_dfa(DFA_E1, \"001\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW4SERPDTIDA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b3aa5ed-bbdc-404b-add9-cb295ed36f6f"
      },
      "source": [
        "accepts_dfa(DFA_B0, \"000\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpOifuRITIDA"
      },
      "source": [
        "DFA_B0_and_E1 = intersect_dfa(DFA_B0, DFA_E1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL8mqmreTIDA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "7dcf8db5-8b94-4fd1-ea55-4144acfa5803"
      },
      "source": [
        "dotObj_dfa(DFA_B0_and_E1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fe32fc97710>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"389pt\" height=\"291pt\"\n viewBox=\"0.00 0.00 388.88 290.64\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 286.6442)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-286.6442 384.8835,-286.6442 384.8835,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- \\(I_I\\) -->\n<g id=\"node3\" class=\"node\">\n<title>\\(I_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-106.1471\" rx=\"27.0966\" ry=\"27.0966\"/>\n<text text-anchor=\"middle\" x=\"118.2976\" y=\"-102.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n</g>\n<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-106.1471C62.6976,-106.1471 71.9683,-106.1471 80.8159,-106.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-109.6472 90.9246,-106.1471 80.9246,-102.6472 80.9247,-109.6472\"/>\n</g>\n<!-- \\(F_I\\) -->\n<g id=\"node2\" class=\"node\">\n<title>\\(F_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"226.7422\" cy=\"-180.1471\" rx=\"29.795\" ry=\"29.795\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-176.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge7\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.2832,-208.19C215.8184,-219.0325 219.3047,-228.0444 226.7422,-228.0444 231.6231,-228.0444 234.8023,-224.1633 236.2799,-218.4307\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.791,-218.4634 237.2012,-208.19 232.8192,-217.8361 239.791,-218.4634\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-231.8444\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\) -->\n<g id=\"node5\" class=\"node\">\n<title>\\(F_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"344.3864\" cy=\"-180.1471\" rx=\"32.4945\" ry=\"32.4945\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"344.3864\" cy=\"-180.1471\" rx=\"36.4942\" ry=\"36.4942\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-176.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge6\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M256.7332,-180.1471C269.1018,-180.1471 283.7299,-180.1471 297.4563,-180.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"297.725,-183.6472 307.7249,-180.1471 297.7249,-176.6472 297.725,-183.6472\"/>\n<text text-anchor=\"middle\" x=\"283.8893\" y=\"-183.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge2\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M141.0311,-121.6599C156.1574,-131.9817 176.287,-145.7176 193.2374,-157.2842\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.5352,-160.3599 201.7682,-163.1054 195.4808,-154.5778 191.5352,-160.3599\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-146.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\) -->\n<g id=\"node4\" class=\"node\">\n<title>\\(B_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"226.7422\" cy=\"-33.1471\" rx=\"33.2948\" ry=\"33.2948\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-29.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge9\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M141.0311,-90.8439C155.417,-81.16 174.3283,-68.4298 190.7262,-57.3914\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.6939,-60.286 199.035,-51.7983 188.7849,-54.4791 192.6939,-60.286\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-77.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge3\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M221.4973,-66.1065C221.6033,-76.2941 223.3516,-84.2941 226.7422,-84.2941 228.8614,-84.2941 230.339,-81.1691 231.175,-76.3381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"234.6848,-76.3521 231.9871,-66.1065 227.7068,-75.7982 234.6848,-76.3521\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-88.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge4\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.8985,-65.1546C214.711,-84.2871 217.9922,-102.2941 226.7422,-102.2941 233.9199,-102.2941 237.4177,-90.1769 237.2354,-75.2612\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"240.7202,-74.9095 236.586,-65.1546 233.7346,-75.3585 240.7202,-74.9095\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-106.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge5\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M338.7834,-216.3083C339.0031,-226.6612 340.8708,-234.6442 344.3864,-234.6442 346.6386,-234.6442 348.2145,-231.368 349.114,-226.2913\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"352.6024,-226.5758 349.9894,-216.3083 345.6292,-225.9643 352.6024,-226.5758\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-238.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge8\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M333.6747,-215.2073C331.6752,-234.6969 335.2458,-252.6442 344.3864,-252.6442 351.8846,-252.6442 355.6346,-240.5672 355.6364,-225.4688\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"359.1172,-225.0101 355.0981,-215.2073 352.1268,-225.3769 359.1172,-225.0101\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-256.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbtEvJQvTIDB"
      },
      "source": [
        "DFA_B0_or_E1 = union_dfa(DFA_B0, DFA_E1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-KSf_tNTIDB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "7045ea86-d749-44af-b18b-7f86566f47af"
      },
      "source": [
        "dotObj_dfa(DFA_B0_or_E1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fe32f8c90f0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"397pt\" height=\"303pt\"\n viewBox=\"0.00 0.00 396.88 302.64\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 298.6442)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-298.6442 392.8835,-298.6442 392.8835,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- \\(I_I\\) -->\n<g id=\"node2\" class=\"node\">\n<title>\\(I_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-114.1471\" rx=\"27.0966\" ry=\"27.0966\"/>\n<text text-anchor=\"middle\" x=\"118.2976\" y=\"-110.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n</g>\n<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-114.1471C62.6976,-114.1471 71.9683,-114.1471 80.8159,-114.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-117.6472 90.9246,-114.1471 80.9246,-110.6472 80.9247,-117.6472\"/>\n</g>\n<!-- \\(F_I\\) -->\n<g id=\"node3\" class=\"node\">\n<title>\\(F_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-192.1471\" rx=\"29.8071\" ry=\"29.8071\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-192.1471\" rx=\"33.795\" ry=\"33.795\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-188.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge2\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M140.7822,-129.7441C156.0937,-140.3653 176.703,-154.6614 194.3322,-166.8904\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.4993,-169.8785 202.7109,-172.7024 196.4891,-164.1269 192.4993,-169.8785\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-156.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\) -->\n<g id=\"node5\" class=\"node\">\n<title>\\(B_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-37.1471\" rx=\"33.2788\" ry=\"33.2788\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"230.7422\" cy=\"-37.1471\" rx=\"37.2947\" ry=\"37.2947\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-33.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge9\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M141.0524,-98.565C155.4794,-88.6857 174.5289,-75.6409 191.3601,-64.1152\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"193.6499,-66.7892 199.9233,-58.2513 189.6949,-61.0136 193.6499,-66.7892\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-86.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge7\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M219.4929,-224.3291C219.4338,-235.2592 223.1836,-244.0444 230.7422,-244.0444 235.7025,-244.0444 239.0225,-240.2609 240.7022,-234.5707\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"244.215,-234.688 241.9915,-224.3291 237.2698,-233.8136 244.215,-234.688\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-247.8444\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\) -->\n<g id=\"node4\" class=\"node\">\n<title>\\(F_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"352.3864\" cy=\"-192.1471\" rx=\"32.4945\" ry=\"32.4945\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"352.3864\" cy=\"-192.1471\" rx=\"36.4942\" ry=\"36.4942\"/>\n<text text-anchor=\"middle\" x=\"352.3864\" y=\"-188.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge6\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M264.9506,-192.1471C277.6062,-192.1471 292.1767,-192.1471 305.7491,-192.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"305.8853,-195.6472 315.8853,-192.1471 305.8852,-188.6472 305.8853,-195.6472\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-195.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge5\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M346.7834,-228.3083C347.0031,-238.6612 348.8708,-246.6442 352.3864,-246.6442 354.6386,-246.6442 356.2145,-243.368 357.114,-238.2913\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"360.6024,-238.5758 357.9894,-228.3083 353.6292,-237.9643 360.6024,-238.5758\"/>\n<text text-anchor=\"middle\" x=\"352.3864\" y=\"-250.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge8\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M341.6747,-227.2073C339.6752,-246.6969 343.2458,-264.6442 352.3864,-264.6442 359.8846,-264.6442 363.6346,-252.5672 363.6364,-237.4688\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"367.1172,-237.0101 363.0981,-227.2073 360.1268,-237.3769 367.1172,-237.0101\"/>\n<text text-anchor=\"middle\" x=\"352.3864\" y=\"-268.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge3\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M225.145,-74.0009C225.3902,-84.35 227.2559,-92.2941 230.7422,-92.2941 232.9756,-92.2941 234.544,-89.0339 235.4472,-83.9696\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"238.934,-84.2732 236.3394,-74.0009 231.9618,-83.6491 238.934,-84.2732\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-96.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge4\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M219.9928,-72.8995C218.077,-92.4173 221.6602,-110.2941 230.7422,-110.2941 238.1923,-110.2941 241.9422,-98.2646 241.9917,-83.1677\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"245.474,-82.7174 241.4917,-72.8995 238.4823,-83.058 245.474,-82.7174\"/>\n<text text-anchor=\"middle\" x=\"230.7422\" y=\"-114.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_S3CUCgTIDB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "24a271a7-4415-49ca-bb01-70face921b69"
      },
      "source": [
        "dotObj_dfa(min_dfa(DFA_B0_or_E1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fe32fc072b0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"269pt\" height=\"142pt\"\n viewBox=\"0.00 0.00 269.39 141.79\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 137.7947)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-137.7947 265.3899,-137.7947 265.3899,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- \\(I_I\\) -->\n<g id=\"node2\" class=\"node\">\n<title>\\(I_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-33.8973\" rx=\"27.0966\" ry=\"27.0966\"/>\n<text text-anchor=\"middle\" x=\"118.2976\" y=\"-30.1973\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n</g>\n<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-33.8973C62.6976,-33.8973 71.9683,-33.8973 80.8159,-33.8973\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-37.3974 90.9246,-33.8973 80.9246,-30.3974 80.9247,-37.3974\"/>\n</g>\n<!-- \\(F_I\\) -->\n<g id=\"node3\" class=\"node\">\n<title>\\(F_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"227.4925\" cy=\"-33.8973\" rx=\"29.8071\" ry=\"29.8071\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"227.4925\" cy=\"-33.8973\" rx=\"33.795\" ry=\"33.795\"/>\n<text text-anchor=\"middle\" x=\"227.4925\" y=\"-30.1973\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge2\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M145.8521,-33.8973C157.106,-33.8973 170.4107,-33.8973 182.9772,-33.8973\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"183.2983,-37.3974 193.2982,-33.8973 183.2982,-30.3974 183.2983,-37.3974\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-37.6973\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge5\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M143.1287,-21.4087C149.6284,-18.7221 156.7397,-16.2769 163.5952,-14.8973 171.4132,-13.3241 179.6519,-13.9743 187.5184,-15.7651\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.6457,-19.1559 197.2239,-18.5617 188.584,-12.4296 186.6457,-19.1559\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-18.6973\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge3\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M222.254,-67.8387C222.4104,-77.937 224.1566,-85.7947 227.4925,-85.7947 229.5775,-85.7947 231.0414,-82.7253 231.8844,-77.9578\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"235.385,-78.0957 232.731,-67.8387 228.4093,-77.512 235.385,-78.0957\"/>\n<text text-anchor=\"middle\" x=\"227.4925\" y=\"-89.5947\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge4\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M217.6084,-66.6147C215.5025,-85.8191 218.7972,-103.7947 227.4925,-103.7947 234.6254,-103.7947 238.1241,-91.6987 237.9887,-76.7509\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"241.4731,-76.3855 237.3766,-66.6147 234.4859,-76.8075 241.4731,-76.3855\"/>\n<text text-anchor=\"middle\" x=\"227.4925\" y=\"-107.5947\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "uHH3EvxzTIDB"
      },
      "source": [
        "## DFA complementation\n",
        "\n",
        "DFA complementation works by flipping the final and non-final states. We must check that the DFA is totalized before we embark on that, as the 'black-hole' state will now become 'white-hole' (a final state from which all symbols lead back to itself)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "-qhweQ4rTIDC"
      },
      "source": [
        "def comp_dfa(D):\n",
        "    \"\"\"In : D (DFA : partially consistent)\n",
        "       Out: Consistent DFA that is D's complement.\n",
        "       Before we begin, make D total. This is crucial, \n",
        "       as the black-hole states if any\n",
        "       become \"white-hole\" states in the complemented DFA \n",
        "       (i.e. really turn into accepting \n",
        "       states from which one can't get out).\n",
        "       Then flip the FINAL and NON-FINAL states.\n",
        "    \"\"\"\n",
        "    Dtot = totalize_dfa(D)\n",
        "    return mk_dfa(D[\"Q\"],D[\"Sigma\"],D[\"Delta\"],D[\"q0\"],D[\"Q\"]-D[\"F\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyKsQIVITIDC"
      },
      "source": [
        "DFA_comp_B0_or_E1 = comp_dfa(DFA_B0_or_E1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK9SfHeNTIDC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "699e656d-20bf-46ee-c63e-0cc5840ae962"
      },
      "source": [
        "dotObj_dfa(DFA_comp_B0_or_E1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fe32fc10470>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"389pt\" height=\"287pt\"\n viewBox=\"0.00 0.00 388.88 286.64\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 282.6442)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-282.6442 384.8835,-282.6442 384.8835,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- \\(I_I\\) -->\n<g id=\"node5\" class=\"node\">\n<title>\\(I_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122.2976\" cy=\"-106.1471\" rx=\"27.1222\" ry=\"27.1222\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"122.2976\" cy=\"-106.1471\" rx=\"31.0965\" ry=\"31.0965\"/>\n<text text-anchor=\"middle\" x=\"122.2976\" y=\"-102.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n</g>\n<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.0536,-106.1471C62.3696,-106.1471 71.722,-106.1471 80.7745,-106.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.7965,-109.6472 90.7964,-106.1471 80.7964,-102.6472 80.7965,-109.6472\"/>\n</g>\n<!-- \\(F_I\\) -->\n<g id=\"node2\" class=\"node\">\n<title>\\(F_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"234.7422\" cy=\"-180.1471\" rx=\"29.795\" ry=\"29.795\"/>\n<text text-anchor=\"middle\" x=\"234.7422\" y=\"-176.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge7\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M224.2832,-208.19C223.8184,-219.0325 227.3047,-228.0444 234.7422,-228.0444 239.6231,-228.0444 242.8023,-224.1633 244.2799,-218.4307\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"247.791,-218.4634 245.2012,-208.19 240.8192,-217.8361 247.791,-218.4634\"/>\n<text text-anchor=\"middle\" x=\"234.7422\" y=\"-231.8444\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\) -->\n<g id=\"node3\" class=\"node\">\n<title>\\(F_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"348.3864\" cy=\"-180.1471\" rx=\"32.4942\" ry=\"32.4942\"/>\n<text text-anchor=\"middle\" x=\"348.3864\" y=\"-176.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge6\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M264.8984,-180.1471C277.3697,-180.1471 292.0573,-180.1471 305.608,-180.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"305.6933,-183.6472 315.6932,-180.1471 305.6932,-176.6472 305.6933,-183.6472\"/>\n<text text-anchor=\"middle\" x=\"291.8893\" y=\"-183.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge5\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M343.1415,-212.6877C343.2475,-222.7458 344.9958,-230.6442 348.3864,-230.6442 350.5055,-230.6442 351.9831,-227.5589 352.8192,-222.7893\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"356.3186,-222.936 353.6313,-212.6877 349.3411,-222.375 356.3186,-222.936\"/>\n<text text-anchor=\"middle\" x=\"348.3864\" y=\"-234.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge8\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M338.5843,-211.4982C336.3143,-230.5827 339.5817,-248.6442 348.3864,-248.6442 355.609,-248.6442 359.1054,-236.4904 358.8758,-221.588\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"362.3601,-221.2372 358.1885,-211.4982 355.3763,-221.713 362.3601,-221.2372\"/>\n<text text-anchor=\"middle\" x=\"348.3864\" y=\"-252.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_F\\) -->\n<g id=\"node4\" class=\"node\">\n<title>\\(B_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"234.7422\" cy=\"-33.1471\" rx=\"33.2948\" ry=\"33.2948\"/>\n<text text-anchor=\"middle\" x=\"234.7422\" y=\"-29.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge3\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M229.4973,-66.1065C229.6033,-76.2941 231.3516,-84.2941 234.7422,-84.2941 236.8614,-84.2941 238.339,-81.1691 239.175,-76.3381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.6848,-76.3521 239.9871,-66.1065 235.7068,-75.7982 242.6848,-76.3521\"/>\n<text text-anchor=\"middle\" x=\"234.7422\" y=\"-88.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge4\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M224.8985,-65.1546C222.711,-84.2871 225.9922,-102.2941 234.7422,-102.2941 241.9199,-102.2941 245.4177,-90.1769 245.2354,-75.2612\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"248.7202,-74.9095 244.586,-65.1546 241.7346,-75.3585 248.7202,-74.9095\"/>\n<text text-anchor=\"middle\" x=\"234.7422\" y=\"-106.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge2\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M148.6608,-123.4968C164.3596,-133.8281 184.4338,-147.039 201.2473,-158.104\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.4245,-161.0943 209.702,-163.6681 203.2727,-155.247 199.4245,-161.0943\"/>\n<text text-anchor=\"middle\" x=\"177.5952\" y=\"-149.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge9\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M148.6608,-89.0318C163.3392,-79.5025 181.8428,-67.4898 197.9296,-57.0461\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"200.0969,-59.812 206.5785,-51.4312 196.2852,-53.9408 200.0969,-59.812\"/>\n<text text-anchor=\"middle\" x=\"177.5952\" y=\"-77.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8Q66UNnTIDC"
      },
      "source": [
        "DFA_comp_compB0_or_compE1 = comp_dfa(union_dfa(comp_dfa(DFA_B0), comp_dfa(DFA_E1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zisKgXpETIDC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "b2f26862-8edd-43e7-adf6-340cdded6534"
      },
      "source": [
        "dotObj_dfa(DFA_comp_compB0_or_compE1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fe32fc10630>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"389pt\" height=\"291pt\"\n viewBox=\"0.00 0.00 388.88 290.64\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 286.6442)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-286.6442 384.8835,-286.6442 384.8835,4 -4,4\"/>\n<!-- EMPTY -->\n<g id=\"node1\" class=\"node\">\n<title>EMPTY</title>\n</g>\n<!-- \\(I_I\\) -->\n<g id=\"node3\" class=\"node\">\n<title>\\(I_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118.2976\" cy=\"-106.1471\" rx=\"27.0966\" ry=\"27.0966\"/>\n<text text-anchor=\"middle\" x=\"118.2976\" y=\"-102.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(I_I)</text>\n</g>\n<!-- EMPTY&#45;&gt;\\(I_I\\) -->\n<g id=\"edge1\" class=\"edge\">\n<title>EMPTY&#45;&gt;\\(I_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.3923,-106.1471C62.6976,-106.1471 71.9683,-106.1471 80.8159,-106.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.9247,-109.6472 90.9246,-106.1471 80.9246,-102.6472 80.9247,-109.6472\"/>\n</g>\n<!-- \\(F_I\\) -->\n<g id=\"node2\" class=\"node\">\n<title>\\(F_I\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"226.7422\" cy=\"-180.1471\" rx=\"29.795\" ry=\"29.795\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-176.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_I)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge7\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.2832,-208.19C215.8184,-219.0325 219.3047,-228.0444 226.7422,-228.0444 231.6231,-228.0444 234.8023,-224.1633 236.2799,-218.4307\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"239.791,-218.4634 237.2012,-208.19 232.8192,-217.8361 239.791,-218.4634\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-231.8444\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\) -->\n<g id=\"node5\" class=\"node\">\n<title>\\(F_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"344.3864\" cy=\"-180.1471\" rx=\"32.4945\" ry=\"32.4945\"/>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"344.3864\" cy=\"-180.1471\" rx=\"36.4942\" ry=\"36.4942\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-176.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(F_F)</text>\n</g>\n<!-- \\(F_I\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge6\" class=\"edge\">\n<title>\\(F_I\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M256.7332,-180.1471C269.1018,-180.1471 283.7299,-180.1471 297.4563,-180.1471\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"297.725,-183.6472 307.7249,-180.1471 297.7249,-176.6472 297.725,-183.6472\"/>\n<text text-anchor=\"middle\" x=\"283.8893\" y=\"-183.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(F_I\\) -->\n<g id=\"edge2\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(F_I\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M141.0311,-121.6599C156.1574,-131.9817 176.287,-145.7176 193.2374,-157.2842\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"191.5352,-160.3599 201.7682,-163.1054 195.4808,-154.5778 191.5352,-160.3599\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-146.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\) -->\n<g id=\"node4\" class=\"node\">\n<title>\\(B_F\\)</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"226.7422\" cy=\"-33.1471\" rx=\"33.2948\" ry=\"33.2948\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-29.4471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(B_F)</text>\n</g>\n<!-- \\(I_I\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge9\" class=\"edge\">\n<title>\\(I_I\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M141.0311,-90.8439C155.417,-81.16 174.3283,-68.4298 190.7262,-57.3914\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.6939,-60.286 199.035,-51.7983 188.7849,-54.4791 192.6939,-60.286\"/>\n<text text-anchor=\"middle\" x=\"169.5952\" y=\"-77.9471\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge3\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M221.4973,-66.1065C221.6033,-76.2941 223.3516,-84.2941 226.7422,-84.2941 228.8614,-84.2941 230.339,-81.1691 231.175,-76.3381\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"234.6848,-76.3521 231.9871,-66.1065 227.7068,-75.7982 234.6848,-76.3521\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-88.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(B_F\\)&#45;&gt;\\(B_F\\) -->\n<g id=\"edge4\" class=\"edge\">\n<title>\\(B_F\\)&#45;&gt;\\(B_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.8985,-65.1546C214.711,-84.2871 217.9922,-102.2941 226.7422,-102.2941 233.9199,-102.2941 237.4177,-90.1769 237.2354,-75.2612\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"240.7202,-74.9095 236.586,-65.1546 233.7346,-75.3585 240.7202,-74.9095\"/>\n<text text-anchor=\"middle\" x=\"226.7422\" y=\"-106.0941\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge5\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M338.7834,-216.3083C339.0031,-226.6612 340.8708,-234.6442 344.3864,-234.6442 346.6386,-234.6442 348.2145,-231.368 349.114,-226.2913\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"352.6024,-226.5758 349.9894,-216.3083 345.6292,-225.9643 352.6024,-226.5758\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-238.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 </text>\n</g>\n<!-- \\(F_F\\)&#45;&gt;\\(F_F\\) -->\n<g id=\"edge8\" class=\"edge\">\n<title>\\(F_F\\)&#45;&gt;\\(F_F\\)</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M333.6747,-215.2073C331.6752,-234.6969 335.2458,-252.6442 344.3864,-252.6442 351.8846,-252.6442 355.6346,-240.5672 355.6364,-225.4688\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"359.1172,-225.0101 355.0981,-215.2073 352.1268,-225.3769 359.1172,-225.0101\"/>\n<text text-anchor=\"middle\" x=\"344.3864\" y=\"-256.4442\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 </text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "FZT0rkxUTIDD"
      },
      "source": [
        "## DFA Union\n",
        "\n",
        "DFA union has a straightforward definition as in the book. We march the DFAs in tandem. We accept if either DFA accepts_dfa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "zF1uvl1DTIDD"
      },
      "source": [
        "def union_dfa(D1in, D2in):\n",
        "    \"\"\"In : D1in (consistent DFA)\n",
        "            D2in (consistent DFA)\n",
        "       Out: DFA for language union of D1in, D2in (consistent DFA). \n",
        "    \"\"\"\n",
        "    assert(is_consistent_dfa(D1in)), \"Inconsist. DFA1 in union_dfa\"\n",
        "    assert(is_consistent_dfa(D2in)), \"Inconsist. DFA2 in union_dfa\"\n",
        "    if (D1in[\"Sigma\"] != D2in[\"Sigma\"]):\n",
        "        print(\"Union on DFA with different alphabets.\")\n",
        "        print(\"Making alphabets the same (taking unions).\")\n",
        "        Sigma = D1in[\"Sigma\"] | D2in[\"Sigma\"]\n",
        "        D1   = copy.deepcopy(D1in)\n",
        "        D2   = copy.deepcopy(D2in)\n",
        "        D1[\"Sigma\"] = Sigma\n",
        "        D2[\"Sigma\"] = Sigma\n",
        "        D1 = totalize_dfa(D1)\n",
        "        D2 = totalize_dfa(D2)\n",
        "    else:\n",
        "        D1 = totalize_dfa(D1in)\n",
        "        D2 = totalize_dfa(D2in)\n",
        "   \n",
        "    # The states can be anything in the cartesian product\n",
        "    Q     = set(product(D1[\"Q\"], D2[\"Q\"]))\n",
        "    \n",
        "    # Accept if one of the DFAs accepts\n",
        "    F     = (set(product(D1[\"F\"], D2[\"Q\"])) | \n",
        "             set(product(D1[\"Q\"], D2[\"F\"])))\n",
        "    \n",
        "    # Start a lock-step march from the respective q0\n",
        "    q0    = (D1[\"q0\"], D2[\"q0\"])\n",
        "    \n",
        "    # The transition function attempts to march both\n",
        "    # DFAs in lock-step per their own transition functions\n",
        "    Delta = { ((q1,q2),ch) : (q1p, q2p) \n",
        "               for q1 in D1[\"Q\"] for q1p in D1[\"Q\"] \n",
        "               for q2 in D2[\"Q\"] for q2p in D2[\"Q\"] \n",
        "               for ch in D1[\"Sigma\"] \n",
        "               if D1[\"Delta\"][(q1,ch)] == q1p and\n",
        "                  D2[\"Delta\"][(q2,ch)] == q2p }\n",
        "                                                          \n",
        "    return pruneUnreach(\n",
        "        mk_dfa(Q, D1[\"Sigma\"], Delta, q0, F))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "U7AkBzJ0TIDD"
      },
      "source": [
        "def intersect_dfa(D1in, D2in):\n",
        "    \"\"\"In : D1in (consistent DFA)\n",
        "            D2in (consistent DFA)\n",
        "       Out: DFA for language intersection of D1in, D2in (consistent DFA). \n",
        "    \"\"\"\n",
        "    assert(is_consistent_dfa(D1in)), \"Inconsist. DFA1 in intersect_dfa\"\n",
        "    assert(is_consistent_dfa(D2in)), \"Inconsist. DFA2 in intersect_dfa\"\n",
        "    if (D1in[\"Sigma\"] != D2in[\"Sigma\"]):\n",
        "        print(\"Intersection on DFA with different alphabets.\")\n",
        "        print(\"Making alphabets the same (taking unions).\")\n",
        "        Sigma = D1in[\"Sigma\"] | D2in[\"Sigma\"]\n",
        "        D1   = copy.deepcopy(D1in)\n",
        "        D2   = copy.deepcopy(D2in)\n",
        "        D1[\"Sigma\"] = Sigma\n",
        "        D2[\"Sigma\"] = Sigma\n",
        "        D1 = totalize_dfa(D1)\n",
        "        D2 = totalize_dfa(D2)\n",
        "    else:\n",
        "        D1 = totalize_dfa(D1in)\n",
        "        D2 = totalize_dfa(D2in)\n",
        " \n",
        "    Q     = set(product(D1[\"Q\"], D2[\"Q\"]))\n",
        "    \n",
        "    # This is the only difference with the union:\n",
        "    # The final states are those when both DFA accept\n",
        "    F     = set(product(D1[\"F\"], D2[\"F\"]))\n",
        "           \n",
        "    q0    = (D1[\"q0\"], D2[\"q0\"])\n",
        "    Delta = { ((q1,q2),ch) : (q1p, q2p) \n",
        "               for q1 in D1[\"Q\"] for q1p in D1[\"Q\"] \n",
        "               for q2 in D2[\"Q\"] for q2p in D2[\"Q\"] \n",
        "               for ch in D1[\"Sigma\"] \n",
        "               if D1[\"Delta\"][(q1,ch)] == q1p and\n",
        "                  D2[\"Delta\"][(q2,ch)] == q2p }\n",
        "                                                          \n",
        "    return pruneUnreach(\n",
        "        mk_dfa(Q, D1[\"Sigma\"], Delta, q0, F))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "KWIw0ba0TIDE"
      },
      "source": [
        "### Eliminating unreachable states\n",
        "\n",
        "Let us write the code for eliminating unreachable states. Function pruneUnreach(DFA) returns a new DFA with unreachable states in the input DFA removed (all transitions from them are also removed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "D0A4bfmBTIDH"
      },
      "source": [
        "def pruneUnreach(D):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "       Out: Consistent DFA.\n",
        "       Given a consistent (and of course total) DFA D,\n",
        "       returns a new (consistent) DFA with unreachable \n",
        "       states in D removed. Transitions from each unreachable \n",
        "       state are also removed. Reachable states are those that\n",
        "       can be reached in |D[\"Q\"]| - 1 steps or less.\n",
        "    \"\"\"\n",
        "    Nsteps   = len(D[\"Q\"]) - 1 # Search this far\n",
        "    Frontier = set({D[\"q0\"]})  # BFS frontier\n",
        "    AccumF   = Frontier        # Used to accumulate Frontier changes\n",
        "    for n in range(Nsteps):\n",
        "        for q in Frontier:\n",
        "            for ch in D[\"Sigma\"]:\n",
        "                AccumF = AccumF | set({step_dfa(D, q, ch)})\n",
        "        Frontier = AccumF\n",
        "        \n",
        "    newQ     = Frontier\n",
        "    newF     = D[\"F\"] & Frontier\n",
        "    newDelta = dict({ ((q,ch),qp) \n",
        "                      for ((q,ch),qp) in fn_trans(D[\"Delta\"]) \n",
        "                      if q in Frontier })\n",
        "    return mk_dfa(Frontier, D[\"Sigma\"], newDelta, D[\"q0\"], newF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "qQKmcvx8TIDI"
      },
      "source": [
        "# DFA Isomorphism\n",
        "\n",
        "This routine is handy to check whether two DFA are isomorphic. Given they are rooted at q0, the isomorphism-check is linear in the number of edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "et_HMH0rTIDI"
      },
      "source": [
        "def iso_dfa(D1,D2):\n",
        "    \"\"\"Given consistent and total DFAs D1 and D2,\n",
        "       check whether they are isomorphic. Two DFAs\n",
        "       are isomorphic if they have the same number\n",
        "       of states and are language-equivalent. (One would\n",
        "       then be able to match-up state for state and transition\n",
        "       for transition.)\n",
        "    \"\"\"\n",
        "    assert(is_consistent_dfa(D1)), \"Inconsist. DFA1 in iso_dfa\"\n",
        "    assert(is_consistent_dfa(D2)), \"Inconsist. DFA2 in iso_dfa\"\n",
        "    return (len(D1[\"Q\"]) == len(D2[\"Q\"]) and\n",
        "            langeq_dfa(D1, D2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "dqBXbD4kTIDI"
      },
      "source": [
        "def langeq_dfa(D1, D2, gen_counterex=False):\n",
        "    \"\"\"Given consistent and total DFAs D1 and D2,\n",
        "       check whether they are language-equivalent. \n",
        "       gen_counterex is a flag that triggers the\n",
        "        printing of a counter-example showing the\n",
        "        pairs that were marched in tandem till a\n",
        "        difference was found.\n",
        "        \n",
        "       Two DFAs are language-equivalent if they \n",
        "       accept the same set of strings. We determine\n",
        "       this through a joint depth-first walk of the \n",
        "       two DFAs until we detect a difference (return\n",
        "       False then) or all pairs of states have been\n",
        "       visited (return True then).\n",
        "    \"\"\"\n",
        "    if D1[\"Sigma\"] != D2[\"Sigma\"]:\n",
        "        print(\"The DFA cannot be compared, as their\", end=\"\")\n",
        "        print(\" alphabets are different; namely:\")\n",
        "        print(\"Sigma1 = \", D1[\"Sigma\"])\n",
        "        print(\"Sigma2 = \", D2[\"Sigma\"])\n",
        "        return False\n",
        "    else:\n",
        "        (eqStatus, cex_path) = h_langeq_dfa(D1[\"q0\"], D1,\n",
        "                                            D2[\"q0\"], D2, \n",
        "                                            Visited=[])\n",
        "        if not eqStatus:\n",
        "            if gen_counterex:\n",
        "                print(\"The DFA are NOT language equivalent!\")\n",
        "                print(\"Path leading to counterexample is: \")\n",
        "                print(cex_path)\n",
        "        return eqStatus # True or False\n",
        "\n",
        "def same_status(q1, D1, q2, D2):\n",
        "    \"\"\"Check if q1,q2 are both accepting\n",
        "       or both non-accepting wrt D1,D2 resply.\n",
        "    \"\"\"\n",
        "    return (q1 in D1[\"F\"]) == (q2 in D2[\"F\"])\n",
        "\n",
        "def h_langeq_dfa(q1, D1, q2, D2, Visited):\n",
        "    \"\"\"Helper for langeq_dfa. \n",
        "       If (q1,q2) is in Visited, no screw-up so far, so\n",
        "        continue. Else if they agree in status, recursively\n",
        "        check for all reachable configurations (a DFS in\n",
        "        recursion). Else (if they differ in status),\n",
        "        then return (False, Visited) where the latter is\n",
        "        the counter-example trace.  \n",
        "    \"\"\"\n",
        "    if (q1,q2) in Visited:\n",
        "        return (True, Visited)\n",
        "    else:\n",
        "        extVisited = Visited + [(q1,q2)]\n",
        "        if not same_status(q1,D1,q2,D2):\n",
        "            return (False, extVisited)\n",
        "        else:\n",
        "            l_nxt_status = list(\n",
        "            map(lambda symb:\n",
        "                h_langeq_dfa(D1[\"Delta\"][(q1,symb)], D1,\n",
        "                             D2[\"Delta\"][(q2,symb)], D2,\n",
        "                             extVisited),\n",
        "                D1[\"Sigma\"]))\n",
        "            l_rejects = list(filter(lambda x: x[0]==False, l_nxt_status))\n",
        "            if l_rejects==[]:\n",
        "                return (True, extVisited)\n",
        "            else:\n",
        "                return l_rejects[0] # which is the first offending (status,cex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pxv2BLyTIDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884f30d9-ffc9-4fef-f3ce-9fb42c3a88e7"
      },
      "source": [
        "langeq_dfa( DFA_comp_compB0_or_compE1 , DFA_B0_and_E1 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCpthloaTIDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3b813f-4490-4703-b263-da97b84aa717"
      },
      "source": [
        "iso_dfa( DFA_comp_compB0_or_compE1 , DFA_B0_and_E1 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2CR7C1jTIDK"
      },
      "source": [
        "min_DFA_B0_or_E1 = min_dfa(DFA_B0_or_E1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWA9aNVmTIDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60f0551-89ab-42d5-d500-818555a8e17a"
      },
      "source": [
        "langeq_dfa(DFA_B0_or_E1, min_DFA_B0_or_E1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSAYDc5ETIDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344c8c14-9d35-43c2-ba9f-de37c00d1640"
      },
      "source": [
        "iso_dfa(DFA_B0_or_E1, min_DFA_B0_or_E1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "U4rF7tuETIDL"
      },
      "source": [
        "# DFA Minimization\n",
        "\n",
        "This is a good juncture at which to introduce DFA minimization. \n",
        "\n",
        "## Definition of DFA minimization\n",
        "\n",
        "We define minimization only for consistent DFA.\n",
        " \n",
        "> _A consistent DFA D is minimal if it satisfies two properties_\n",
        " \n",
        ">  1. There should not be any unreachable states (from the start state) in it\n",
        " \n",
        ">  2. For any pair of distinct states $(s_1,s_2)$ in $D$, we must not have the case that for all strings $s$ in $\\Sigma^*$, $\\hat{\\delta}(s_1,s) = \\hat{\\delta}(s_2,s)$.\n",
        "\n",
        "\n",
        "We don't want useless states and we don't want redundant states. For instance, let me make a redundant DFA with duplicate states, below. Then you can easily see how even bloated DFAs can recognize the same language. After seeing this fact, we will introduce you to a DFA minimization algorithm.\n",
        "\n",
        "First, let's learn how to deliberately bloat a DFA:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "UjZPMUo6TIDL"
      },
      "source": [
        "## DFA minimization algorithm (high level)\n",
        "\n",
        "Having seen two examples of bloated DFA, we now define a minimization algorithm. Here is the gist. The actual algorithm is in the code that follows.\n",
        "\n",
        "1. Put the states into two equivalence classes (EC):\n",
        "\n",
        " a. All non-final states are in one EC, say NF\n",
        " b. All final states are in another EC, say F\n",
        " c. We call any (sa,sb) such that sa in NF and sb in F as **zero-distinguishable** states, as \n",
        "    a $\\varepsilon$ string can distinguish sa and sb (meaning, when sa is evolved through $\\varepsilon$ or $sb$ is evolved through $\\varepsilon$, the resulting state is the same -- sa or sb)\n",
        "    \n",
        "     * \"Evolved through\" means $\\hat{\\delta}(sa,\\varepsilon) = sa$, and similarly for sb\n",
        "     \n",
        "     * In our example DFA d34bl, IF is zero-distinguishable from all other states\n",
        " \n",
        "2. In general, we have $k$-distinguishable states for $k>0$ (above step discussed $k=0$ as zero-distinguishability)\n",
        "\n",
        "3. Split states:\n",
        " \n",
        " a. Take a state pair $(s_1,s_2)$ such that they are not $k$ distinguishable.\n",
        " b. Take $c\\in\\Sigma$\n",
        " c. If $\\delta(s_1,c) = sn_1$ and $\\delta(s_2,c) = sn_2$ and $(sn_1,sn_2)$ are $k$-distinguishable, mark $(s_1,s_2)$ as $k+1$-distinguishable. \n",
        " \n",
        "4. Repeat the above process till across one sweep, the distinguishability relation does not change.\n",
        "\n",
        "5. Take all maximal sets of pairs of states that have not been found distinguishable yet. Pick a representative from each such maximal set. These states are in the final DFA. \n",
        "\n",
        "6. Go by the state transitions of the representative states. (The remaining states in the equivalence classes are not necessary.)\n",
        "\n",
        "  * In our example, all pairs in $\\{A,A1\\} \\times \\{B,B1\\}$ will be 1-distinguishable (distinction made by $0$)\n",
        "  \n",
        "  * The final equivalence classes will be $\\{IF\\}$, and then $\\{A,A1\\}$, and $\\{B,B1\\}$.\n",
        "  \n",
        "\n",
        "<span style=\"color:blue\"> **Clearly, the above algorithm cannot make full sense till you see how it can be worked out \"by hand\" using some pictures. This is what we will now do before showing you the actual code.\n",
        "\n",
        "** </span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "s5L3anqBTIDL"
      },
      "source": [
        "## A fully worked-out example\n",
        "\n",
        "<font size=\"3\"> \n",
        "\n",
        "This is the initial display of a matrix (only the lower half shown, as the upper half is symmetric). The matrix shows \".\" which are points at which state pairs \"collide.\" The dots in this figure allow for these pairs to collide (we show pairs only one way, i.e. (P,Q) and not the other way i.e. (Q,P) also).\n",
        "\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "4TRWVo9VTIDM"
      },
      "source": [
        "<font size=\"4\"> \n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "A   .\n",
        "\n",
        "A1  .   .\n",
        "\n",
        "B   .   .   .\n",
        "\n",
        "B1  .   .   .   .\n",
        "\n",
        "    IF  A   A1  B\n",
        "    \n",
        "The above is a convenient arrangement to talk about these pairs:\n",
        "\n",
        "\n",
        "(A, IF),\n",
        "\n",
        "(A1, IF), (A1, A)\n",
        "\n",
        "(B, IF),  (B, A),  (B, A1)\n",
        "\n",
        "(B1, IF), (B1, A), (B1, A1), (B1, B)\n",
        "\n",
        "Now, here is how the computation proceeds for this example:\n",
        "===========================================================\n",
        "\n",
        "Frame-0              Frame-1                Frame-2                \n",
        " \n",
        "A   -1                A   0                  A   0                 \n",
        "\n",
        "A1  -1   -1           A1  0   -1             A1  0   -1            \n",
        " \n",
        "B   -1   -1  -1       B   0   -1   -1        B   0   1   1         \n",
        "\n",
        "B1  -1   -1  -1  -1   B1  0   -1   -1  -1    B1  0   1   1   -1    \n",
        "\n",
        "    IF   A   A1  B        IF  A    A1  B         IF  A   A1  B         \n",
        "    \n",
        "    \n",
        "Frame-3 = Frame-2   \n",
        "\n",
        "A   0 \n",
        "\n",
        "A1  0   -1\n",
        "\n",
        "B   0   1   1\n",
        "\n",
        "B1  0   1   1   -1\n",
        "\n",
        "    IF  A   A1  B   \n",
        "``` \n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Let's see another example as well. We will explain the second \n",
        "example (we leave the above example wrt **D34bl** as something you can explain).\n",
        "\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "PE_kNRswTIDM"
      },
      "source": [
        "\n",
        "Now, here is how the computation proceeds for this example:\n",
        "-------------------------------------------------------- \n",
        " \n",
        " <br>\n",
        " \n",
        "<font size=\"3\"> \n",
        "\n",
        "\n",
        "```\n",
        " \n",
        "Frame-0                  Frame-1                   Frame-2                    \n",
        "                                                                                                     \n",
        "S2  -1                   S2   0                    S2   0                     \n",
        "\n",
        "S3  -1  -1               S3   0  -1                S3   0  -1                 \n",
        "\n",
        "S4  -1  -1  -1           S4  -1   0   0            S4   2   0   0             \n",
        "\n",
        "S5  -1  -1  -1  -1       S5  -1   0   0  -1        S5   2   0   0  -1         \n",
        "\n",
        "S6  -1  -1  -1  -1  -1   S6   0  -1  -1   0   0    S6   0   1   1   0   0     \n",
        "\n",
        "    S1  S2  S3  S4  S5       S1  S2  S3  S4  S5        S1  S2  S3  S4  S5        \n",
        "\n",
        "Initial                  0-distinguishable         1-distinguishable                         \n",
        "     \n",
        "     \n",
        "Frame-3                 Frame-4     \n",
        "                        =\n",
        "                        Frame-3\n",
        "\n",
        "S2   0\n",
        "\n",
        "S3   0  -1\n",
        "\n",
        "S4   2   0   0\n",
        "\n",
        "S5   2   0   0  -1\n",
        "\n",
        "S6   0   1   1   0   0\n",
        "\n",
        "    S1  S2  S3  S4  S5\n",
        "    \n",
        "2-distinguishable \n",
        "     \n",
        "```\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "yuwZ2NBeTIDM"
      },
      "source": [
        "Here is the algorithm, going frame by frame.\n",
        "\n",
        "- Initial Frame: \n",
        "\n",
        "     The initial frame is drawn to clash all _combinations_ of states taken two at a time.\n",
        "     Since we have 6 states, we have $6\\choose 2$ = $15$ entries. We put a -1 against each\n",
        "     such pair to denote that they have not been found distinguishable yet.\n",
        "\n",
        "- Frame *0-distinguishable*: We now put a 0 where a pair of states is 0-distinguishable. This means the states are distinguisable after consuming $\\varepsilon$. This of course means that the states are themselves distinguishable. This is only possible if one is a final state and the other is not (in that case, one state, after consuming $\\varepsilon$ accepts_dfa, and another state after consuming $\\varepsilon$ does not accept.\n",
        "\n",
        "  - So for instance, notice that (S3,S1) and (S4,S2) are 0-distinguishable, meaning that one is a final and the other is a non-final state.\n",
        "\n",
        "- Frame *1-distinguishable*: We now put a 1 where a pair of states is 1-distinguishable. This means the states are distinguisable after consuming a string of length $1$ (a single symbol). This is only possible if one state transitions to a final state and the other transitions to a non-final state after consuming a member of $\\Sigma$. \n",
        "\n",
        "  State pairs (S6,S2) and (S6,S3) are of this kind. While both S6 and S2 are final states (hence _0-indistinguishable_), after consuming an 'a' (or a 'b') they respectively go to a final/non-final state.\n",
        " This means that\n",
        "\n",
        "  - after processing **the same symbol** one state -- let's say pre_p -- finds itself landing in a state p and another state  -- let's say pre_q -- finds itself landing in a state q such that (p,q) is 0-distinguishable.\n",
        "  \n",
        "  - When this happens, states pre-p and pre-q are **1-distinguishable**.\n",
        "\n",
        "- Frame *2-distinguishable*: We now put a 2 where a pair of states is 2-distinguishable. This means the states are distinguisable after consuming a string of length $2$ (a string of length $2$). This is only possible if one state transitions to a state (say p) and the other transitions to state (say q) after consuming a member of $\\Sigma$ such that (p,q) is **1-distinguishable**. State pairs (S5,S1) and (S4,S1) are 2-distinguishable because\n",
        "\n",
        "  - after processing **the same symbol** one state -- let's say pre_p -- finds itself landing in a state p and another state  -- let's say pre_q -- finds itself landing in a state q such that (p,q) is 0-distinguishable.\n",
        "  \n",
        "  - When this happens, states pre-p and pre-q are **1-distinguishable**.\n",
        "  \n",
        "  - One example is this:\n",
        "  \n",
        "    - S5 and S1 are 2-distinguishable.\n",
        "    \n",
        "    - This is because after seeing an 'aa', S1 lands in a non-final state while S5 lands in a final state\n",
        "    \n",
        "    - Observe that \"aa\" = \"a\" + \"a\" . Thus, after eating the first \"a\", S1 lands in S2 while S5 lands in S6, and (S2,S6) have already been deemed 1-distinguishable.\n",
        "    \n",
        "    - Thus, when we mark (S5,S1) as 2-distinguishable, we are sending the matrix entry at (S5,S2) from \n",
        "      -1 to 2\n",
        " \n",
        "\n",
        "\n",
        "  - Now, in search of 3-distinguishability, we catch hold of all pairs in the matrix and see if we can send another -1 entry to \"3\". This appears not to happen. \n",
        "  \n",
        "     - Thus, if (S2,S3) is pushed via any sequence of symbols (any string) of any length, it\n",
        "       always stays in the same type of state. Thus, after seeing 'ababba', S2 is in S6, while S3 \n",
        "        is also in S6.\n",
        "\n",
        "\n",
        " - Thus, given no changes in the matrix, we stop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "DRZl9IRmTIDM"
      },
      "source": [
        "## Code for DFA minimization\n",
        "\n",
        "We now provide the code for DFA minimization, referring to the above narrative to keep us focused as to which part of the algorithm we are implementing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "QrijNa7PTIDM"
      },
      "source": [
        "### The heart of the algorithm is function fixptDist. This seeks the fixpoint (or \"fixed-point\") of the Dist (or Distinguishability) relation. Neat eh?\n",
        "\n",
        "A fixpoint of a function f is a value x such that f(x) = x. In our case, the functiion in question is one that take the entire matrix (frame) and tries to spit out the next matrix (frame). When we get a matrix m such that f(m) = m, the matrix has stabilized.\n",
        "\n",
        "In our case, we obtain a fixpoint of the function with respect to input value \"ht\" (hash-table) representing our matrix. We also pass along the DFA in question (\"D\") that is a read-only argument (to consult its transition function, etc).\n",
        "\n",
        "See how the code speaks for itself:\n",
        "\n",
        "* We set \"changed = True\" outside a while loop, and enter this loop \"while changed\".\n",
        "\n",
        "* We set changed = False, hoping to get out\n",
        "\n",
        "  - Any change-causing activity (n-distinguishability for some n) will set changed back to True\n",
        "  \n",
        "  - If not, we will \"get out of the jail\"\n",
        "  \n",
        "  - Termination is guaranteed. Why?\n",
        "    \n",
        "      * There are only a finite number of states\n",
        "      \n",
        "      * If we pump a long-enough string from a pair of states,\n",
        "      \n",
        "          - Clearly, it can try to meander, visiting fresh state pairs that are m-distinguishable for \n",
        "             an m <= n (those other state pairs and their distinguishability distance\n",
        "             were generated in an earlier pass or the current pass)\n",
        "             \n",
        "      * In short, for any pair of states (p,q), there is a maximal (loop-free) string s such that \n",
        "        $\\hat{\\delta}(p,s) \\in F$ while $\\hat{\\delta}(q,s)\\in (Q\\setminus F)$. This is the highest the \n",
        "        distinguishability number can get to.\n",
        "             \n",
        "           - If $s$ has a loop, there is a shorter string that establishes the distinguishability \n",
        "              number.\n",
        "         \n",
        "         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "z6rPc-FATIDM"
      },
      "source": [
        "We now go through all aspects of the code:\n",
        "\n",
        "* We first iterate across \"kv\" (key,value) pairs in ht.items(), i.e. we iterate through all \n",
        "  the matrix entries (pairs) which are recorded in \"ht\" (the hash table). The value recorded is the\n",
        "  distinguishability number.\n",
        "  \n",
        "* We obtain s0 and s1, the states that this hash-table entry is modeling.\n",
        "\n",
        "* We iterate across all $c\\in\\Sigma$\n",
        "\n",
        "* We obtain the next state after sending s0 and s1 via $c$\n",
        "\n",
        "* If we land in the same next state (ns0 == ns1), we continue (try to \"get out of the jail\" by not\n",
        "  resetting changed)\n",
        "  \n",
        "* If this is a visited pair (i.e. (ns0,ns1) in ht), then\n",
        "\n",
        "  - If one is \"-1\" while the other is >= 0  (meaning they are distinguishable states)\n",
        "     \n",
        "       - then we set changed = True, and continue, breaking this iteration of the \"for c\"\n",
        "       \n",
        "       - else we examine it as pair (ns1, ns0). This is because \"ht\" does not store both \n",
        "          (ns0,ns1) and (ns1,ns0). But we have to check both ways\n",
        "          \n",
        "       - we apply the same logic\n",
        "       \n",
        "* If we can find distinguishability, we increase the ht number\n",
        "\n",
        "* else we will get out of the loop!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "O5vdlhdNTIDN"
      },
      "source": [
        "def fixptDist(D, ht):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "            ht (hash-table of distinguishability pair distances)\n",
        "       Out: ht that has attained a fixpoint in distinguishability.\n",
        "       Helper (but main workhorse) for min_dfa.\n",
        "       Given an initial hash-table ht and a DFA D to be minimized,\n",
        "       determine the min. distinguishability distances, going frame \n",
        "       by frame, as illustrated in the DFA minimization algorithm. \n",
        "       Return fixpoint ht. Fixpoint is when ht ceases to change.\n",
        "    \"\"\"\n",
        "    changed = True\n",
        "    while changed:\n",
        "        changed = False\n",
        "        for kv in ht.items():\n",
        "            s0 = kv[0][0]\n",
        "            s1 = kv[0][1]\n",
        "            for c in D[\"Sigma\"]:\n",
        "                ns0 = D[\"Delta\"][(s0,c)]\n",
        "                ns1 = D[\"Delta\"][(s1,c)]\n",
        "                #\n",
        "                # Distinguishable state pairs carry \n",
        "                # \"distinguishability distance\" in the ht\n",
        "                if ns0 == ns1:\n",
        "                    continue\n",
        "                if (ns0, ns1) in ht:\n",
        "                    # s0,s1 are distinguishable\n",
        "                    if ht[(s0,s1)] == -1 and ht[(ns0, ns1)] >= 0: \n",
        "                        # acquire one more than the\n",
        "                        # dist. number of (ns0,ns1)\n",
        "                        ht[(s0,s1)] = ht[(ns0, ns1)] + 1          \n",
        "                        changed = True                            \n",
        "                        break\n",
        "                else:\n",
        "                    # ht stores only (ns0,ns1); \n",
        "                    # so check the other way\n",
        "                    if (ns1, ns0) in ht:                              \n",
        "                        if ht[(s0,s1)] == -1 and ht[(ns1, ns0)] >= 0:  \n",
        "                            ht[(s0,s1)] = ht[(ns1, ns0)] + 1           \n",
        "                            changed = True                             \n",
        "                            break                                      \n",
        "                    else:                                              \n",
        "                        print(\"ht doesn't cover all reqd state combos.\")\n",
        "    return ht"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "1cIbDw-XTIDN"
      },
      "source": [
        "def min_dfa(D, state_name_mode='succinct'):  # Default state mode\n",
        "    \"\"\"In : D (consistent DFA to be minimized)\n",
        "       Out: Minimized version of D.\n",
        "       The top-level callable DFA minimizer.\n",
        "       Given a DFA D, go through the state minimization algorithm.\n",
        "       state_name_mode is 'verbose' or 'succinct', producing two \n",
        "       variants, as you can guess.\n",
        "       If the state_name_mode is verbose, we will make state names\n",
        "       by stringing together the state names in the equivalence\n",
        "       classes. Else we keep the name of the representative of \n",
        "       each equivalence class.\n",
        "    \"\"\"\n",
        "    if (len(D[\"Q\"]) == 1): # Already minimal\n",
        "        return D\n",
        "    else:\n",
        "        # Build a dict of all state combinations of DFA.\n",
        "        # Function state_combos also imparts a -1 for each state pair,\n",
        "        # initializing the separation distance at -1.  \n",
        "        ht = dict(state_combos(list(D[\"Q\"])))\n",
        "    \n",
        "        # Mark final and non-final states to be 0-distinguishable.\n",
        "        # This is achieved by putting a 0 against those state pairs.\n",
        "        sepFinNonFin(D, ht)\n",
        "    \n",
        "        # Main fixpoint computation: Assigning distinguishability dist. \n",
        "        #==============================================================\n",
        "        ht = fixptDist(D, ht)\n",
        "    \n",
        "        # Pick out equivalent state-pairs, i.e. those that cannot be \n",
        "        # distinguished. These are still with a \"-1\" in ht.\n",
        "        ht_1 = [ stpair for (stpair, dist) in ht.items() if dist == -1 ]\n",
        "    \n",
        "        # Now form equivalence classes\n",
        "        # what's returned is \n",
        "        # [(rep_1, [all_eql_states_1]), (rep_2, [all_eql_states_2]),...]\n",
        "        # which includes all equivalence classes of size 2 or more.\n",
        "        rep_eqc = bash_eql_classes(ht_1)\n",
        "\n",
        "        # Now we have to deal with singleton equivalence classes. \n",
        "        # These sit unmerged, OUTSIDE OF ALL (x,y) in ht_1\n",
        "        # i.e. all the entries in ht_1 are PARTNERED STATE PAIRS.  \n",
        "    \n",
        "        # If we now take D[\"Q\"] and subtract from it all those x and y\n",
        "        # which are present in some pair in ht_1, we obtain completely\n",
        "        # non-mergable states. These are states in their own eql. classes.\n",
        "    \n",
        "        # 1. Find all partnered states from ht_1\n",
        "        Partnered_states = list({x for (x,y) in ht_1} |\n",
        "                                {y for (x,y) in ht_1})\n",
        "    \n",
        "        # 2. Now who is left un-partnered?\n",
        "        List_of_self_only_eqlt_states = listminus(D[\"Q\"], Partnered_states)                     \n",
        "    \n",
        "        # 3. For these singletons, i.e. \"self-only equivalent states\", \n",
        "        # they are self-representative. Form pairs that indicate this fact.\n",
        "        rep_eqc_1 = [(x, [x]) for x in List_of_self_only_eqlt_states]\n",
        "    \n",
        "        # 4. OK now, we can combine the set of pairs where each pair is \n",
        "        # (representative, [the list of equivalent states])\n",
        "        # So finally we get the list of equivalence classes with \n",
        "        # representatives  which is of this form:\n",
        "        # [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...] \n",
        "        final_rep_eqc = rep_eqc + rep_eqc_1\n",
        "    \n",
        "        # We are now ready to build a DFA out of final_rep_eqc. \n",
        "        # =====================================================\n",
        "    \n",
        "        # 1. First, form the set of minimized states, which are \n",
        "        # state representatives.\n",
        "        minQ = {x for (x,y) in final_rep_eqc}\n",
        "    \n",
        "        # 2. The Alpbahet remains the same.\n",
        "        minSigma = D[\"Sigma\"]\n",
        "    \n",
        "        # 3. The starting state is the representative of D[\"q0\"]\n",
        "        minq0 = q0_of(D[\"q0\"], final_rep_eqc)\n",
        "    \n",
        "        # 4. The final states are the representatives of the original\n",
        "        #    final states. This is computed by helper F_of.\n",
        "        minF = F_of(D[\"F\"], final_rep_eqc)\n",
        "    \n",
        "        # 5. The transition relation of the minimized DFA is obtained\n",
        "        #    by the helper Delta_of\n",
        "        minDelta = Delta_of(D[\"Delta\"], final_rep_eqc)\n",
        "    \n",
        "        # 6. We now need to rename the states if the user wants verbose \n",
        "        #    names (default is succinct). Verbose names are the name of \n",
        "        #    states in each equivalence class strung together sep by \"_\".\n",
        "        if state_name_mode == 'verbose':\n",
        "            # First build a state-renaming hash-table involving \n",
        "            # mk_state_eqc_name\n",
        "            state_rename_ht = { x : mk_state_eqc_name(y) \n",
        "                                for (x,y) in final_rep_eqc }\n",
        "        \n",
        "            minQ            = { state_rename_ht[x] for x in minQ }\n",
        "            minq0           = state_rename_ht[minq0]\n",
        "            minF            = { state_rename_ht[f] for f in minF }\n",
        "            minDelta = { (state_rename_ht[x], y) : state_rename_ht[z] \n",
        "                         for ((x,y),z) in minDelta.items() }\n",
        "        #\n",
        "        # Return the finished (minimized) DFA!\n",
        "        return mk_dfa(minQ, minSigma, minDelta, minq0, minF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "hU3EM69DTIDN"
      },
      "source": [
        "def pairFR(L):\n",
        "    \"\"\"In : L (list of states)\n",
        "       Out: List of pairs with L[0] paired with each state in L[1:],\n",
        "            with the distinguishability distance initialized to -1.\n",
        "       Helper for generating state_combos.\n",
        "    \"\"\"\n",
        "    return list(map(lambda x: ((L[0], x), -1), L[1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "eHEt7YDETIDN"
      },
      "source": [
        "def state_combos(L):\n",
        "    \"\"\"In : L (list of states)\n",
        "       Out: List of combinations of L's states (rep. as pairs),\n",
        "            with distinguishability distances marked as -1. \n",
        "       Helper for min_dfa.\n",
        "       Given a list of DFA states L (assume length >= 2),\n",
        "       Form state combinations, paired up as (L[i], L[i+1]).\n",
        "       This forms the 'ht' that is acted upon by fixptDist.\n",
        "    \"\"\"\n",
        "    if len(L) <= 2:\n",
        "        return([((L[0], L[1]), -1)])\n",
        "    else:\n",
        "        return (pairFR(L)) + (state_combos(L[1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "csG6MovDTIDN"
      },
      "source": [
        "def sepFinNonFin(D, ht):\n",
        "    \"\"\"In : D (consistent DFA)\n",
        "            ht (hash table of distinguishability distances)\n",
        "       Out: ht with (nonfinal,final) pairs in ht\n",
        "            marked with a distinguishability distance of 0.\n",
        "       Helper for min_dfa.\n",
        "       Given a hash-table of separation distances and a DFA D,\n",
        "       mark each state pair (final,non-final) with value 0\n",
        "       indicating their 0-distinguishability.\n",
        "    \"\"\"\n",
        "    # Form a separation predicate \n",
        "    sepPred = lambda x,y: (x in D[\"F\"] and y in (D[\"Q\"] - D[\"F\"]) or \n",
        "                           y in D[\"F\"] and x in (D[\"Q\"] - D[\"F\"]))\n",
        "                         \n",
        "    # Now separate all states where sepPred holds\n",
        "    for kv in ht.items():\n",
        "        if sepPred(kv[0][0], kv[0][1]):\n",
        "            # Mark that this pair is 0-distinguishable\n",
        "            ht[kv[0]] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "UoQa727WTIDN"
      },
      "source": [
        "def bash_eql_classes(eql_reln):\n",
        "    \"\"\"In : eql_reln (equivalence relation : list of pairs of states).\n",
        "       Out: List of equivalence classes with representatives.\n",
        "            I.e. a structure of the form\n",
        "            [ (state0, [state0, state1, state2,]), ... ]\n",
        "            where state0 is a representative for the three (for example)\n",
        "            equivalent states state0, state1, state2. There are as many\n",
        "            such pairs as equivalence classes.\n",
        "       Helper for min_dfa.\n",
        "       Given an Eql. reln. of the form \n",
        "       [(a,b),(a,c),(d,e),(f,h),(g,f),..].\n",
        "       1. Grow eql classes \n",
        "       2. Elect a representative for each eql class\n",
        "       3. Return \"equivalence classes with representatives.\"\n",
        "       This is a structure of the form\n",
        "        [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...] \n",
        "       where \"a0\" is a state and a0,a1,a2,a3,a4 are equivalent to it\n",
        "       The same goes for the bs, cs, etc.\n",
        "    \"\"\"\n",
        "    return bash_1(eql_reln, []) # seed with empty list of eql class sets."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "ANwKC7q0TIDO"
      },
      "source": [
        "def listminus(L1, L2):\n",
        "    \"\"\"In : L1 : list or set\n",
        "            L2 : list or set\n",
        "       Out: List of items in L1 that are not in L2.\n",
        "       Helper for min_dfa and bash_1. Implements subtraction (L1 - L2).\n",
        "    \"\"\"\n",
        "    return [x for x in L1 if x not in L2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "U0ylk_TZTIDO"
      },
      "source": [
        "def bash_1(eql_reln, L_eq_classes):\n",
        "    \"\"\"In : eql_reln (equivalence relation : list of pairs of eqlt states)\n",
        "            L_eq_classes (list of eql classes which are SETS of states \n",
        "            for now.)\n",
        "       Out: return list of equivalence classes with representatives.\n",
        "       Helper for bash_eql_classes. \n",
        "       1) eql_reln is the current equivalence relation \n",
        "          (list of pairs)\n",
        "       2) L_eq_classes is a list of sets that are the eqlt \n",
        "          classes coalesced thus far.\n",
        "       3) We remove one pair at a time from the eql_reln and find\n",
        "          existing equivalence classes to expand, thus modifying\n",
        "          L_eq_classes each time. \n",
        "       Once the equivalence relation is emptied, we call mk_rep_eqc\n",
        "       thus making a list of equivalence classes with representatives\n",
        "       of the form \n",
        "       [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...]. \n",
        "    \"\"\"\n",
        "    if eql_reln == []:\n",
        "        # When we have fully processed the given equivalence \n",
        "        # relation, return a list of equivalence classes with \n",
        "        # representatives of the form \n",
        "        # [(a0,[a0, a1, a2, a3, a4]), (b0,[b0, b1]), (c0,[c0]), ...]\n",
        "        return mk_rep_eqc(L_eq_classes)\n",
        "    else:\n",
        "        # pick the next pair from the eql_reln being coalesced\n",
        "        eq0 = eql_reln[0]   \n",
        "        a = eq0[0]          \n",
        "        b = eq0[1]   \n",
        "        \n",
        "        # We know that a is a state that is equivalent to b, since\n",
        "        # they exist as a pair in eql_reln[0].\n",
        "        \n",
        "        # Now we must see if 'a' already lives in a COALESCED \n",
        "        # equivalence class\n",
        "   \n",
        "        # Set Sa is a typical equivalence class in L_eq_classes\n",
        "        # See if 'a' is in Sa.\n",
        "        \n",
        "        SaL = [Sa for Sa in L_eq_classes if a in Sa]\n",
        "        \n",
        "        # There must be zero or one such set as Sa. \n",
        "        # Thus, |SaL| = 0 or 1\n",
        "        \n",
        "        # Similarly, see which (if any) eql class that b lives in\n",
        "        SbL = [Sb for Sb in L_eq_classes if b in Sb]  \n",
        "        \n",
        "        # Now there are four cases:\n",
        "        \n",
        "        # 1. a,b pair is totally new (not in any eql. class so far)\n",
        "        if (SaL == [] and SbL == []):\n",
        "            # Add a fresh eql class {a,b} to L_eq_classes and recurse\n",
        "            return bash_1(eql_reln[1:], [{a,b}] + L_eq_classes)\n",
        "        \n",
        "        # 2. a is in eql class SaL[0] while b is not in any eql class\n",
        "        elif (SbL == [] and not(SaL == [])):\n",
        "            # Remove the little eql. class in which 'a' sits\n",
        "            # replace by a bigger eql. class that now also includes 'b'. \n",
        "            # That is, we must invite 'b' into the same eql class \n",
        "            # in which 'a' sits (this being SaL[0]).\n",
        "            \n",
        "            # Then we take away the eql class that 'a' sits in from \n",
        "            # L_eq_classes, and of course replace it with an expanded \n",
        "            # version that includes b\n",
        "            New_L_eq_classes = (listminus(L_eq_classes, SaL) +\n",
        "                                [SaL[0] | {b}])\n",
        "            \n",
        "            return bash_1(eql_reln[1:], New_L_eq_classes)\n",
        "        \n",
        "        # 3. b is in eql class SbL[0] while a is not in any eql class\n",
        "        elif (SaL == [] and not(SbL == [])):\n",
        "            # Similar steps as above, with 'a' being invited in.\n",
        "            \n",
        "            New_L_eq_classes = (listminus(L_eq_classes, SbL) +\n",
        "                                [SbL[0] | {a}])\n",
        "            \n",
        "            return bash_1(eql_reln[1:], New_L_eq_classes)\n",
        "        \n",
        "        else:\n",
        "            # a and b are both in their own little eql. classes\n",
        "            # We must now collapse both the eql classes into a huge one\n",
        "            # Remove both little pre-existing eql. classes. Replace \n",
        "            # with union-ed one. Neither 'a' nor 'b' is being invited in\n",
        "            # afresh; rather, the eql classes they are in \n",
        "            # (i.e. SaL[0],SbL[0]) are being merged.\n",
        "            \n",
        "            New_L_eq_classes = (listminus(L_eq_classes,SaL+SbL) + \n",
        "                                [SaL[0] | SbL[0]])\n",
        "            \n",
        "            return bash_1(eql_reln[1:], New_L_eq_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "ufs5UTR9TIDO"
      },
      "source": [
        "def mk_rep_eqc(L_eq_classes):\n",
        "    \"\"\"Helper for bash_1 that finds the representative of a set of\n",
        "       equivalent states. Given the final equivalence classes,\n",
        "       make representatives for each; stick the repr. at the \n",
        "       head of a pair. Thus, (repr, eql-class-with-repr) list\n",
        "       is returned.\n",
        "    \"\"\"\n",
        "    Ll = list(map(lambda x: list(x), L_eq_classes))\n",
        "    return list(map(lambda x: (x[0], x), Ll))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "qFXYwa3hTIDO"
      },
      "source": [
        "def F_of(F, final_rep_eqc):\n",
        "    \"\"\"In : F (final states of DFA)\n",
        "            final_rep_eqc : equivalence class with representatives\n",
        "       Out: A set of representatives of the final states \n",
        "       Helper for min_dfa.\n",
        "       Given F, the final states of a DFA and final equivalence\n",
        "       classes with representatives of the form \n",
        "       [(rep,[states eql to rep], ...)\n",
        "       obtain those equivalence classes in which the original final \n",
        "       states live. Form a set of the representatives of these states. \n",
        "       This will be the set of representatives of the final states.\n",
        "    \"\"\"\n",
        "    return { x for (x,X) in final_rep_eqc \n",
        "             if not (set(F) & set(X)) == set({}) }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "DRJDI2EBTIDO"
      },
      "source": [
        "def rep_of_s(s, final_rep_eqc):\n",
        "    \"\"\"Helper for min_dfa. Given a list \n",
        "       [(rep_of_s1, [states_eql_to_s1]),...]\n",
        "       that has states paired with the list of equivalent states, \n",
        "       return the representative of s.\n",
        "    \"\"\"\n",
        "    if final_rep_eqc == []:\n",
        "        print(\"Error, did not find a rep for state s\")\n",
        "    else:\n",
        "        x_X = final_rep_eqc[0]\n",
        "        if s in x_X[1]:\n",
        "            return x_X[0]\n",
        "        else:\n",
        "            return q0_of(s, final_rep_eqc[1:])    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "LJYVvCvlTIDO"
      },
      "source": [
        "def q0_of(q0, final_rep_eqc):\n",
        "    \"\"\"Helper for min_dfa. Given the initial state of the DFA and\n",
        "       the list [(rep, [eql states]), ...], find the representative\n",
        "       of q0 in lieu of q0.\n",
        "    \"\"\"\n",
        "    return rep_of_s(q0, final_rep_eqc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "cofa_OSkTIDP"
      },
      "source": [
        "def Delta_of(Delta, final_rep_of_eqc):\n",
        "    \"\"\"In : Delta (transition function of the given DFA)\n",
        "            final_rep_of_eqc (eql classes with representatives)\n",
        "       Out: Form a dict of representatives' moves.\n",
        "       Helper for min_dfa. \n",
        "       Given the original transition function Delta and the\n",
        "       list [(rep_of_eqc, [equivalent states,...]), ...], \n",
        "       produce a new transition function with state representatives \n",
        "       (not the original states) jumping around!\n",
        "       The nice thing is that if multiple states had jumped around, \n",
        "       their transitions AUTOMATICALLY GET MERGED when we pool \n",
        "       the transitions into a hash-table (dictionary). Thus, we are \n",
        "       merging transitions among equivalent states also.\n",
        "    \"\"\"\n",
        "    return { (rep_of_s(s0, final_rep_of_eqc), a): \n",
        "              rep_of_s(s1, final_rep_of_eqc)  \n",
        "              for  ((s0,a),s1) in Delta.items() }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "f714SMQpTIDP"
      },
      "source": [
        "def mk_state_eqc_name(L):\n",
        "    \"\"\"In : List of states (in each eql class)\n",
        "       Out: single state names by bashing the states separated by \"_\".\n",
        "       Helper for min_dfa. \n",
        "       Given a list of states, bash the \n",
        "       state names together separated by an underscore. \n",
        "       This is useful when 'verbose mode' state name printing \n",
        "       is desired.\n",
        "    \"\"\"\n",
        "    return \"_\".join(L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2GzGHuWVYFt"
      },
      "source": [
        "#Done\r\n",
        "We read and understood the material."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7PvFzC3Vbsw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}